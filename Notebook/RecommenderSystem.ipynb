{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install emoji\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEXgK6xZv87A",
        "outputId": "b30599c1-41cb-42d3-ee46-d8a29946c1c9"
      },
      "id": "hEXgK6xZv87A",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emojis|"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHQWu-BM-M6s",
        "outputId": "0d6bc623-f19f-4057-afdf-2473efa1adaf"
      },
      "id": "NHQWu-BM-M6s",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyemoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D19r_Wkgw5Dp",
        "outputId": "6afb9aa4-c0c0-4382-ddf6-7e57ea617321"
      },
      "id": "D19r_Wkgw5Dp",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyemoji in /usr/local/lib/python3.7/dist-packages (1.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing specific version :https://pypi.org/project/xgboost/1.3.1/\n",
        "# pip install xgboost==1.3.1\n"
      ],
      "metadata": {
        "id": "m0yCMcjpzehC"
      },
      "id": "m0yCMcjpzehC",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emojis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NfWHuWdAFb8",
        "outputId": "87a2743d-d879-49b2-cfa2-c68f3475b811"
      },
      "id": "0NfWHuWdAFb8",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emojis in /usr/local/lib/python3.7/dist-packages (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "f2peNZKsurZ4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import emojis\n",
        "\n",
        "import string\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer "
      ],
      "id": "f2peNZKsurZ4"
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "scrolled": true,
        "id": "oVMsvrBuurZ-"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow as tf\n",
        "from xgboost import XGBClassifier #1.3.1\n",
        "import pyemoji\n",
        "from cleantext import clean\n",
        "import cv2 as cv\n",
        "import regex as re\n"
      ],
      "id": "oVMsvrBuurZ-"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "vajqLz6luraA"
      },
      "outputs": [],
      "source": [
        "datafile  = pd.read_csv(\"/content/Post1and2.csv\")\n",
        "datafile2 = pd.read_csv(\"/content/Post1and2.csv\")\n",
        "filename = \"/content/ModelForEmojiClf.sav\"\n",
        "emoji_model = pickle.load(open(filename,'rb'))\n"
      ],
      "id": "vajqLz6luraA"
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmXrtWhruraL",
        "outputId": "eca86d90-f979-4035-a13c-72d212bee35e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:79: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ],
      "source": [
        "def classifier(l,c,e,q): \n",
        "    tot_count = e+c\n",
        "    if tot_count >=100: \n",
        "        w = int(l+(e/c)*50)\n",
        "    else: \n",
        "        w = int(l+(e/c)*20)\n",
        "    if q == \"high\": \n",
        "        return round(w)\n",
        "    elif q == \"medium\": \n",
        "        return round(w/2)\n",
        "    else: \n",
        "        return 0\n",
        "\n",
        "def emoji_extractor(sentence): \n",
        "    return [sentence[i] for i in range(len(str(sentence))) if str(sentence[i].encode(\"unicode-escape\"))[2]=='\\\\']\n",
        "\n",
        "def ImageQuality_assement(img): \n",
        "    image = cv.imread(str(img))\n",
        "    y, x = image.shape[0], image.shape[1]\n",
        "    pixel = int(y*x)\n",
        "    if pixel <= 40000: \n",
        "        return \"poor\"\n",
        "    elif pixel > 40000 and pixel <= 150000: \n",
        "        return \"medium\"\n",
        "    else: \n",
        "        return \"high\"\n",
        "def emoji_clf(emoji):\n",
        "    em = str(emoji)\n",
        "    temp = pyemoji.entities(em)[2:-1]\n",
        "    x = len(re.findall('[0-9]+', temp))\n",
        "    if x >0: \n",
        "        arr = np.array(float(temp)).reshape(-1,1)\n",
        "        predicted = emoji_model.predict(arr)\n",
        "        return list(predicted)\n",
        "\n",
        "def extract_emojis(s):\n",
        "    t = len(emojis.get(s))\n",
        "    if t != 0 :\n",
        "        return s\n",
        "    else: \n",
        "        pass\n",
        "def remove_emoji(text): \n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "def remove_url(text):\n",
        "    url_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "def clean_text(text):\n",
        "    delete_dict = {sp_character: '' for sp_character in string.punctuation}\n",
        "    delete_dict[' '] = ' '\n",
        "    table = str.maketrans(delete_dict)\n",
        "    text1 = text.translate(table) \n",
        "    textArr= text1.split()\n",
        "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>2))])\n",
        "    return text2.lower()        \n",
        "    \n",
        "\n",
        "\n",
        "test_data = datafile\n",
        "test_data.dropna(axis = 0, how ='any',inplace=True) \n",
        "test_data['Num_words_text'] = test_data['text'].apply(lambda x:len(str(x).split())) \n",
        "max_test_sentence_length  = test_data['Num_words_text'].max()\n",
        "\n",
        "mask = test_data['Num_words_text'] >2\n",
        "test_data = test_data[mask]\n",
        "\n",
        "\n",
        "\n",
        "test_data['text'] = test_data['text'].apply(remove_emoji)\n",
        "test_data['text'] = test_data['text'].apply(remove_url)\n",
        "test_data['text'] = test_data['text'].apply(clean_text)\n",
        "\n",
        "num_words = 20000 \n",
        "tokenizer = Tokenizer(num_words=num_words, oov_token=\"unk\") \n",
        "tokenizer.fit_on_texts(test_data['text'].tolist()) "
      ],
      "id": "vmXrtWhruraL"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo-wL-z7uraE",
        "outputId": "8f40b259-d674-4019-9307-f8721de493ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_test  = np.array( tokenizer.texts_to_sequences(test_data['text'].tolist()) )\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=40)"
      ],
      "id": "Vo-wL-z7uraE"
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "p40SZCIeuraF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "json_file = open('/content/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/model.h5\")"
      ],
      "id": "p40SZCIeuraF"
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zekrHCcluraG",
        "outputId": "e99fe672-df54-4791-9f38-9ed5baa29a24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 94,  15,  10, ...,   0,   0,   0],\n",
              "       [ 99,  31,   7, ...,   0,   0,   0],\n",
              "       [  4,   3,  14, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [  4,   3,  14, ...,   0,   0,   0],\n",
              "       [ 33, 246,  89, ...,   0,   0,   0],\n",
              "       [ 79,   5,  77, ...,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "x_test "
      ],
      "id": "zekrHCcluraG"
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNaD9V9IuraH",
        "outputId": "04bcbd2f-38a1-4b6a-a0fe-edd935cbcf17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate predictions for all samples\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "print(\"Generate predictions for all samples\")\n",
        "predstate= tf.convert_to_tensor(x_test,dtype=tf.int64)\n",
        "predictions = loaded_model.predict(predstate)\n",
        "predict_results = predictions.argmax(axis=1)"
      ],
      "id": "iNaD9V9IuraH"
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9ax5qwauraJ",
        "outputId": "29a63c18-00a8-4991-f440-fcffe2be5152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "test_data['pred_sentiment']= predict_results\n",
        "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment == 0),'class1',test_data.pred_sentiment)\n",
        "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment == '1'),'class2',test_data.pred_sentiment)\n",
        "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment == '2'),'class3',test_data.pred_sentiment)"
      ],
      "id": "i9ax5qwauraJ"
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "scrolled": true,
        "id": "wp5_LFGpuraM"
      },
      "outputs": [],
      "source": [
        "def recommender_system(filedata,image): \n",
        "    global emojiS,emofil\n",
        "    \n",
        "    txt_data = filedata[['likesCount','text']].dropna()\n",
        "    l = int(txt_data['likesCount'].sum())\n",
        "    print(\"No. of Likes: \",l)\n",
        "    c = int(len(filedata['text']))\n",
        "    print(\"No. of Commontes: \",c)\n",
        "    emojiS = emoji_extractor(\"\".join(list(filedata['text'])))\n",
        "    e = int(len(emojiS))\n",
        "    print(\"No. of emojis: \",e)\n",
        "    q = ImageQuality_assement(str(image))\n",
        "    print(\"ImageQuality: \",q)\n",
        "    Wt = classifier(l,c,e,q)\n",
        "    print(\"No. of Sales Estimated (Wt): \",Wt) \n",
        "    \n",
        "    temp = list(map(extract_emojis,emojiS))\n",
        "    \n",
        "    emofil = [i for i in temp if i is not None]\n",
        "    \n",
        "    emoji_classes = np.array(list(map(emoji_clf,emofil)),ndmin=1)\n",
        "    emoji_classes = list(emoji_classes.flatten())\n",
        "    \n",
        "    print(\"Positive Emoji Count: \",emoji_classes.count([1]))\n",
        "    print(\"negative Emoji Count: \",emoji_classes.count([2]))\n",
        "    print(\"neutral Emoji Count: \",emoji_classes.count([0]))\n",
        "    print()\n",
        "    print() \n",
        "    print(\"Suggestions\")\n",
        "    \n",
        "    if q == \"poor\":\n",
        "        print(\"Need to improve image quality about by 50%\")\n",
        "    elif q == \"medium\": \n",
        "        print(\"Need to improve image quality by 30%\")\n",
        "    else: \n",
        "        form = round(int(c/3))\n",
        "        if emoji_classes.count([2]) >= form:\n",
        "            print(\"suggested to improve the quality of the product\")\n",
        "        elif emoji_classes.count([1]) >= form: \n",
        "            print(\"Good review overall, stay consistent and provide Quality Product\")\n",
        "        elif emoji_classes.count([0]) >= form:\n",
        "            print(\"Improve the quality of the product a bit more\")\n",
        "    \n",
        "    print(\"The text Classification Report\")\n",
        "    print()\n",
        "    print(test_data['pred_sentiment'].value_counts())\n",
        "    \n",
        "    m = max(test_data['pred_sentiment'].value_counts())\n",
        "    print(\"The Maximum Class output is: \",m)\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "id": "wp5_LFGpuraM"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRBYRXYVuraO",
        "outputId": "6b806eca-93b9-47ce-c726-9500ddc470dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of Likes:  38\n",
            "No. of Commontes:  326\n",
            "No. of emojis:  46\n",
            "ImageQuality:  high\n",
            "No. of Sales Estimated (Wt):  45\n",
            "Positive Emoji Count:  3\n",
            "negative Emoji Count:  4\n",
            "neutral Emoji Count:  5\n",
            "\n",
            "\n",
            "Suggestions\n",
            "The text Classification Report\n",
            "\n",
            "class2    22\n",
            "class1     6\n",
            "class3     5\n",
            "Name: pred_sentiment, dtype: int64\n",
            "The Maximum Class output is:  22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "recommender_system(datafile2,\"/content/Post1_2.jpg\")"
      ],
      "id": "vRBYRXYVuraO"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hbsog2_h9KbH"
      },
      "id": "Hbsog2_h9KbH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}